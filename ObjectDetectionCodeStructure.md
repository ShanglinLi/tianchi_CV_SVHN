基于深度学习的目标检测工程的代码结构。整体可以分为CNN特征提取，Priorbox生成及特征提取，匹配和损失计算。  

### 1、CNN特征提取<br>
- **Faster RCNN**
    - 可以选择多种backbone，例如VGG16, ResNet50, ResNet101, ResNet152。

- **SSD**
    - **VGG16基础结构**
        - VGG16的conv1-5<br>
        每个卷积组卷积核大小都是3*3，步长为1，padding为1。每个卷积组后的池化层是2*2卷积核，步长为2。每个卷积组开始的是通道数增大一倍，每个池化层后，特征图尺寸减小一倍。<br>
        conv5后的池化层，卷积核大小是3*3，步长是1，增大感受野（大物体检测），特征图尺寸不变（小物体检测和定位）。
        - conv6<br>
        卷积核大小为3*3，空洞数为6的空洞卷积，padding=6。增大感受野，保证参数量不变，特征图尺寸不变（步长为1）。
        - conv7<br>
        卷积核大小为1*1，输入通道数是1024，输出通道数1024。

    - **深度卷积层**<br>
    conv8，conv9，conv10, conv11。先用1* 1卷积降低通道数，然后用3*3卷积提取特征。


- **YOLO v1**
    - 类似Inception v1<br>
    24个卷积层和2个全连接层，最后输出的特征图大小是7 * 7 * 30。

- **YOLO v2**
    - **DarkNet**<br>
    19个卷积层和5个池化层，增加一个Passthrough层进行特征融合，则一共具有22个卷积层。
        - BN层
        Dropout层在全连接网络中（全连接层后），BN层在卷积网络中（卷积层后，激活函数前）。现在的网络都去掉了全连接层和Dropout层，使用全卷积网络和BN层。
        - 多个3*3卷积替代了7*7卷积
        减小计算量，增加网络深度和非线性能力。
        - Passthrough层
        深浅层进行通道拼接，特征融合，利于小物体检测。
        - 每个区域预测5个边框，每个边框有25个预测值，最后特征图输出维度是125。


- **YOLO v3**
    - **DarkNet-53**<br>
        - DBL模块<br>
        卷积层、BN层和Leaky ReLU层结合。
        - Res 残差模块<br>
        基础网络中使用了大量的残差模型库，从而网络可以设计的很深。
        - 多层特征图<br>
        通过上采样来扩大特征图尺寸，通过通道拼接来融合深浅层特征。
        - 无池化层<br>
        之前的YOLO网络有5个池化层，用来缩小特征图尺寸。这里采用步长为2的卷积核来缩小特征图尺寸。


### 2、先验框的生成和特征提取<br>
- **Faster RCNN**
    - 先验框的生成<br>
    特征图上的每个点对应9个Anchor。

    - 特征提取<br>
    对特征图进行3 * 3卷积，获得每个Anchor的特征。然后并联两个1 * 1卷积网络，用于分类和回归，预测Anchor的类别（正负样本）和位置。分类网络的输出维度是18（9个Anchor，二分类），回归网络的输出维度是36（9个Anchor，4个位置数据）。

- **SSD**
    - 先验框的生成<br>
    conv4，conv7，conv8, conv 9, conv 10, conv11，每个特征图相对于原图的尺度，特征图上的每个点对应4，6，6，6，4，4个priorbox。返回值是原图中的priorbox中心点坐标和宽高。

    - 函数PriorBox<br>
    输入。6个特征图，4个priorbox或6个priorbox的尺寸。<br>
    for 循环遍历6个特征图，for循环遍历特征图上的每个点，求特征图上的每个点在原图中对应的坐标，为priorbox的中心点坐标。根据预先设置的4个priorbox或6个priorbox的尺寸，添加每个priorbox的宽高。<br>
    输出。原图中的所有priorbox的中心点坐标、宽和高。

    - 特征提取<br>
    6个用于检测的特征图，后面分别跟3 * 3卷积网络提取每个priorbox的类别特征，输出维度是126（6个priorbox * 21个类别（20个类别+1个背景）），3 * 3卷积网络提取每个priorbox的位置特征，输出维度是24（6个priorbox * 4个位置数据）。<br>
    根据priorbox的尺寸大小，分配给不同的特征图进行特征提取（小物体用浅层特征图检测，大物体用深层特征图检测）。



- **YOLO v1**



- **YOLO v2**
    - 设定预选框的数量k，通过聚类来确定先验框的尺寸，获得最合适的k个先验框。
    - 预选框的数量和计算量之间权衡。
    - Faset RCNN 和 SSD的预选框尺寸都是人工设计的。

- **YOLO v3**
    - Anchor<br>
    使用聚类算法生成9个Anchor，3个特征图，每个特征图上的每个点预测3个先验框。
    这里有别于SSD，6个特征图，大物体和小物体分别在不同的特征图上。YOLO v3是每个物体都在不同的特征图上进行Anchor生成。
    - 预测输出
    COCO数据集是80个物体类别，4个位置预测，1个置信度预测，特征图上的每个点预测3个预测框，一共3 * 85 = 255维度。
    - 损失函数
    Logistic函数实现多类别预测得分，可以实现类别间解耦，代替Softmax函数。



### 3、匹配和损失计算<br>
- **Faster RCNN**
    - 匹配策略<br>
    正负样本区分，一个Anchor和所有的真实框的最大IoU小于0.3，为负样本；一个真实框，和其有最大IoU的Anchor，为正样本；一个Anchor，和所有真实框的最大IoU大于0.7，为正样本。

    - 难样本挖掘<br>
    一共20000个Anchor，选择256个正负样本(Anchor)进行损失计算。正负样本比例1：1。正样本超过128个，就随机选取。负样本超过128个，就随机选取。

    - 【一阶粗调】类似损失和定位损失计算<br>
    交叉熵函数进行类似损失计算，smooth L1函数进行定位损失计算。
    ***
    - RPN的一个作用是计算Anchor的损失，另一个作用是根据Anchor生成RoI（Anchor->Proposal->RoI）。

    - NMS和生成Proposal<br>
    【一阶粗调】和上面一样生成全部的Anchor，将回归网络得到的回归偏移作用到Anchor使得Anchor更贴近真实值。<br>
    分类网络得到的得分对Anchor进行排序，保留前12000个得分高的Anchor。<br>
    NMS非最大值抑制。检测算法为了保证召回率，一个真实框可以对应多个Anchor。NMS抑制掉重复的候选框。即得分高的边框抑制掉得分低且重叠程度高的边框（2个指标，得分和IoU）。<br>
    剩余的Anchor中根据RPN分类网络输出得分高的前2000个，作为Proposal。<br>

    - 筛选Proposal, 生成RoI<br>
    和RPN筛选Anchor的过程类似。
        - 匹配<br>
        任何一个Proposal，其和所有真实框的最大IoU，大于0.5，为正样本，反之为负样本。
        获得每个RoI的类别真值和回归偏移量真值。
        - 难样本挖掘<br>
        正负样本的总数是256，正负样本比例是1：3，如果数量多了，就随机选取。

    - RCNN<br>
       - 256个RoI的特征经过RoI Pooling，输入全连接网络，然后并联两个分类网络和回归网络，预测类别特征（物体多分类，不是正负样本二分类）和位置特征。
       - 注意，256个RoI没有共享特征，而是单独计算，造成了重复计算。
       - 【二阶细调】分类损失和定位损失计算

- **SSD**
    - 匹配策略<br>
    正负样本区分，一个priorbox和所有的真实框的最大IoU小于0.5，为负样本，反之为正样本。<br>
    正样本匹配，priorbox和其拥有最大IoU的真实框进行匹配。<br>
    保证召回率，和某个真实框有最大IoU的priorbox，即使该IoU不是此priorbox和所有真实框的最大IoU，也要将此priorbox匹配到该真实框。（一个priorbox可以匹配多个真实框，为了保证召回率）

    - 定位损失计算<br>
    正样本和匹配的真实框，可以计算位置预测损失。

    - 难样本挖掘<br>
    计算所有负样本的损失，进行排序，选择损失较大的负样本，数量为正样本数量的3倍。

    - 类别损失计算<br>
    计算正负样本的类似损失。


- **YOLO v1**
    - 先验框生成<br>
    输入图像分为7 * 7个区域，每个区域对应特征图上的一个点。
    每个区域预测两个边框，一共98个预测框。

    - 匹配<br>
    如果一个物体的中心点落在了某个区域，该区域就负责检测该物体。
    该区域的两个预测框中和物体真实框的IoU大的预测框，负责回归该物体的位置。

    - 预测<br>
    最后的特征图大小是7 * 7 * 30，30表示预测的维度，类别概率（VOC 20个物体类别）、边框的置信度（正负样本）、边框的位置（2 * 4）。

    - 损失计算<br>
    正样本中心点坐标损失，正样本宽高损失，正样本置信度损失，正样本类别损失，负样本置信度损失（只判断正负样本，不进行物体类别和定位）。



- **YOLO v2**
    - 匹配<br>
    将预测的位置偏移量作用到先验框，得到预测框的真实位置。
    正样本，一个真实物体的中心点落到了某个区域，该区域就负责检测该物体，将和该物体真实最大IoU的预测框，作为正样本。
    一个预测框和所有物体的真实框的最大IoU小于0.6，视为负样本。
    保证召回率。如果一个预测框被赋予了负样本，后续该预测框是某个物体真实框的最大IoU，还是会被赋予正样本。

    - 损失计算<br>
    先验框和预测框损失，正样本置信度损失、类别损失、位置损失，负样本置信度损失。



- **YOLO v3**
